{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importando Bibliotecas e Dataset de imagens 'mnist'"
      ],
      "metadata": {
        "id": "SKsiZ4nmUbfy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZS1M3HdzoDK"
      },
      "outputs": [],
      "source": [
        "import numpy # importa biblioteca para manipulação de matrizes\n",
        "from matplotlib import pyplot as plt # importa biblioteca para criação de gráficos\n",
        "\n",
        "# Bibliotecas do keras (Para Deep Learning)\n",
        "from keras.datasets import mnist      # importa o dataset mnist\n",
        "from keras.models import Sequential   # importa um modelo sequencial\n",
        "from keras.layers import Dense        # importa camadas totalmente conectadas \n",
        "from keras.layers import Dropout      # importa a estrutura de dropout\n",
        "from keras.utils import np_utils      # importa biblioteca de utilidades do keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Separação em Dados de Treino e de Teste"
      ],
      "metadata": {
        "id": "ZeGFjR1DUpZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() # importa o dataset Mnist da biblioteca Keras\n",
        "\n",
        "# imprime o tamanho do vetor\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xrDiY4g1i0T",
        "outputId": "75db6d30-3f36-410c-e147-f6e1d43aae13"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Exploração de dados "
      ],
      "metadata": {
        "id": "T_j3tb8zXvto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_image = X_train[100] # obtém a imagem de treino no índice 100 do vetor\n",
        "\n",
        "# realiza manipulação dos dados da imagem\n",
        "first_image = numpy.array(first_image, dtype ='float')\n",
        "pixels = first_image.reshape((28,28))\n",
        "\n",
        "# exibe a imagem do vetor\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# imprime o label da imagem de treino do índice 100\n",
        "print('O número da imagem acima é:',y_train[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "MT9IGtav3JsJ",
        "outputId": "d45d8ae5-c1b0-42e1-c5f9-9a868717d9e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número da imagem é: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preciso pegar a quantidade de pixels que cada imagem possui pois isso determinará a quantidade de Neurônios de Entrada (Input Layer) que teremos."
      ],
      "metadata": {
        "id": "GZNeEYpCVuMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando o total de pixels da imagem, multiplicando as suas dimensões\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "print('Número de pixels em cada imagem:',num_pixels)\n",
        "\n",
        "# Transforma os valores dos pixels para float32\n",
        "X_train2 = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test2 = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# Normalizando os valores dos pixels entre 0 e 1\n",
        "X_train2 = X_train2 / 255\n",
        "X_test2 = X_test2 / 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5xWCH0x4biY",
        "outputId": "4157aadf-4471-4f91-bf83-771d180d6907"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de pixels em cada imagem: 784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformando nossos labels em categóricos para podermos usá-los como uma matriz\n",
        "# Em outras palavras, estamos transformando o y em ONE HOT VECTOR\n",
        "y_train_h = np_utils.to_categorical(y_train)\n",
        "y_test_h = np_utils.to_categorical(y_test)\n",
        "\n",
        "# Vamos ver um Exemplo: vimos anteriormente que o número no índice 100 é 5, agora veremos ele representado no formato de matriz\n",
        "print('O número do índice 100 é:',y_train[100])\n",
        "print('O número do índice 100 no formato de matriz é:',y_train_h[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh-z_XmK7Idl",
        "outputId": "4a1fc9f4-1d97-4f41-d38e-8392d27878e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número do índice 100 é: 5\n",
            "O número do índice 100 no formato de matriz é: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo o número de classes do problema, que será igual ao número de neurônios na camada de saída (output layer)\n",
        "num_classes = y_train_h.shape[1]\n",
        "\n",
        "print(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zzz4vVu-gyjD",
        "outputId": "3eaa896f-e53b-45d4-f905-2a18f0bd1532"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Criação do modelo de Rede Neural"
      ],
      "metadata": {
        "id": "3UrWVeJGYKAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando o Modelo Sequencial de RNA\n",
        "model = Sequential([\n",
        "    Dense(units=1024, kernel_initializer='normal', input_dim=num_pixels, activation='relu'), # 1ª camada\n",
        "    Dense(units=2048, kernel_initializer='normal', activation='relu'), # 2ª camada\n",
        "    Dense(units=num_classes,kernel_initializer='normal', activation='softmax') # Camada de Saída\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yGkhOK8kLHt",
        "outputId": "e5b8c9ce-310d-49af-efce-0e4d683e0fca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1024)              803840    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2048)              2099200   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,923,530\n",
            "Trainable params: 2,923,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Treinamento do modelo"
      ],
      "metadata": {
        "id": "egVsuGVCaCfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # compila o modelo criado\n",
        "result = model.fit(X_train2, y_train_h, validation_data=(X_test2,y_test_h), epochs=20, verbose=1, batch_size = 100) # executa o treinamento"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy0ORI1zrgov",
        "outputId": "82666f7b-d65b-40fa-b604-4b6f44a1738e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "600/600 [==============================] - 8s 4ms/step - loss: 0.1808 - accuracy: 0.9454 - val_loss: 0.1043 - val_accuracy: 0.9676\n",
            "Epoch 2/20\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0696 - accuracy: 0.9785 - val_loss: 0.0749 - val_accuracy: 0.9767\n",
            "Epoch 3/20\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0460 - accuracy: 0.9851 - val_loss: 0.0732 - val_accuracy: 0.9791\n",
            "Epoch 4/20\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0347 - accuracy: 0.9885 - val_loss: 0.0893 - val_accuracy: 0.9733\n",
            "Epoch 5/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 0.0711 - val_accuracy: 0.9798\n",
            "Epoch 6/20\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0229 - accuracy: 0.9928 - val_loss: 0.0782 - val_accuracy: 0.9813\n",
            "Epoch 7/20\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.0991 - val_accuracy: 0.9744\n",
            "Epoch 8/20\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.1105 - val_accuracy: 0.9762\n",
            "Epoch 9/20\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0877 - val_accuracy: 0.9809\n",
            "Epoch 10/20\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.1081 - val_accuracy: 0.9789\n",
            "Epoch 11/20\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.1300 - val_accuracy: 0.9751\n",
            "Epoch 12/20\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.1171 - val_accuracy: 0.9775\n",
            "Epoch 13/20\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.0847 - val_accuracy: 0.9822\n",
            "Epoch 14/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.1161 - val_accuracy: 0.9776\n",
            "Epoch 15/20\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.1104 - val_accuracy: 0.9785\n",
            "Epoch 16/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.0958 - val_accuracy: 0.9837\n",
            "Epoch 17/20\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.1169 - val_accuracy: 0.9813\n",
            "Epoch 18/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.1298 - val_accuracy: 0.9793\n",
            "Epoch 19/20\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.1231 - val_accuracy: 0.9799\n",
            "Epoch 20/20\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.1245 - val_accuracy: 0.9813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir do modelo já treinado, farei um teste vendo o resultado que ele me gera para a imagem de índice 100, que vimos anteriormente ser o número 5."
      ],
      "metadata": {
        "id": "EPPQF-TLaJny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# obtém a imagem número 100\n",
        "x = X_train2[100]\n",
        "print(x.shape)\n",
        "\n",
        "# Transformando em 2 dimensões (vetor)\n",
        "x = numpy.expand_dims(x, axis=0)\n",
        "print(x.shape)\n",
        "\n",
        "print('-'*60)\n",
        "\n",
        "# Usaremos o .predict para prever qual o número que o modelo achará para esse índice 100\n",
        "# OBS.: Precisamos passar um vetor para essa função, por isso usamos o numpy para transformar a imagem em vetor\n",
        "print('Resultado em formato de matriz:',model.predict(x))\n",
        "\n",
        "print('-'*60)\n",
        "\n",
        "# Função argmax abaixo pega o maior valor de um conjunto que eu passo para ele. Com essa função veremos o número que o modelo achou\n",
        "print('Resultado para o índice 100:',numpy.argmax(model.predict(x))) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bua6WhwSvmvo",
        "outputId": "472c60ab-8a3e-4ad4-ad1c-ba6a00cd0381"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784,)\n",
            "(1, 784)\n",
            "------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Resultado em formato de matriz: [[5.6034882e-11 2.0244221e-12 2.6173508e-11 3.9535903e-09 2.7833211e-17\n",
            "  9.9973160e-01 5.2156149e-05 1.3772785e-14 2.1501111e-04 1.1754117e-06]]\n",
            "------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Resultado para o índice 100: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota-se que o resultado do modelo pode ser interpretado como a probabilidade de uma imagem pertencer a uma das 10 classes disponíveis (números de 0 a 9).\n",
        "\n",
        "Neste caso, ao colhermos o resultado do modelo para o índice 100, ele nos retorna com uma matriz onde a 6ª casa (correspondente ao número 5) possui o maior valor."
      ],
      "metadata": {
        "id": "I-GEgI8ObKHc"
      }
    }
  ]
}