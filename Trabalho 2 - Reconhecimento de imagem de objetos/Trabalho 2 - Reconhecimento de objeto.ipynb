{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRy4xWPRxScW"
      },
      "outputs": [],
      "source": [
        "import numpy # importa biblioteca para manipulação de matrizes\n",
        "from matplotlib import pyplot as plt # importa biblioteca para criação de gráficos\n",
        "\n",
        "# Bibliotecas do keras (Para Deep Learning)\n",
        "from keras.datasets import fashion_mnist                 # importa o dataset fashion_mnist\n",
        "from keras.models import Sequential                      # importa um modelo sequencial\n",
        "from keras.layers import Dense                           # importa camadas totalmente conectadas \n",
        "from keras.layers import Dropout                         # importa a estrutura de dropout\n",
        "from keras.utils import np_utils                         # importa biblioteca de utilidades do keras\n",
        "\n",
        "# Importanto a Rede pré treinada VGG16 para utilizarmos\n",
        "from keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data() # importa o dataset Mnist da biblioteca Keras\n",
        "\n",
        "# imprime o tamanho do vetor\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J_0AQbayU7L",
        "outputId": "c5dd0de7-39a5-4114-e1fd-e3bb2a9e16ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_image = X_train[4000] # obtém a imagem de treino no índice 4000 do vetor\n",
        "\n",
        "# realiza manipulação dos dados da imagem\n",
        "first_image = numpy.array(first_image, dtype ='float')\n",
        "pixels = first_image.reshape((28,28))\n",
        "\n",
        "# exibe a imagem do vetor\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# imprime a classe da imagem de treino do índice 4000\n",
        "print(y_train[4000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6NjH8aqYyqD2",
        "outputId": "3c05be7d-42f0-4ba8-a8db-f323019d3b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAS8ElEQVR4nO3dbYwVZZYH8P/hXZsXaaHblu4VFiVRJ7HHdIhxzKrRJYKJiB8IxEwwGbcnZiZhEj5gnA9jYibRzc7Mzod1TLMamJUFJzIoiboZFscYvhCRsLyoSyMvTpOGBhqkeRc486EL02LXOU3VvbcKzv+XkL5dp5+q51b3oe69p57nEVUFEV3/hhXdASKqDSY7URBMdqIgmOxEQTDZiYIYUcuDiQg/+q+xsWPHmvH6+nozPnz4cDPuVXNOnjyZGjty5IjZlrJRVRlse65kF5HHAPwewHAA/6mqL+fZH1Vea2urGX/66afNuPefxaVLl8z4xo0bU2PLli0z21JlZX4ZLyLDAfwHgNkA7gKwUETuqlTHiKiy8rxnnwlgt6ruUdXzAFYDmFuZbhFRpeVJ9ikA/jbg+65k23eISLuIbBaRzTmORUQ5Vf0DOlXtANAB8AM6oiLlubIfANAy4PvmZBsRlVCeZP8EwB0iMk1ERgFYAGBdZbpFRJUmeUa9icgcAP+O/tLbG6r6a+fnQ76MFxm07PmtvCMPX3311dSYV1pbvHixGX/vvffM+JQp3/uY5jtee+211NioUaPMtvfee68Z91j3CFy8eDHXvsusKnV2VX0fwPt59kFEtcHbZYmCYLITBcFkJwqCyU4UBJOdKAgmO1EQuersV32w67TOXu06+ksvvWTGn3rqqdTY3XffnevY1fTWW2+Z8d7eXjP+3HPPZT52tX9nRUqrs/PKThQEk50oCCY7URBMdqIgmOxEQTDZiYJg6S1RZClm5syZZvyVV14x4w8//HDmY3tTRXtDQYcNs68X3uyzlrffftuMr1mzxoyvWrUqNTZihD3g88KFC2a8zFh6IwqOyU4UBJOdKAgmO1EQTHaiIJjsREEw2YmCqOmSzWXm1dGtOnzeGvySJUvM+DvvvJNr/5a8Uyp7dXSrDu+1XblypRl/9tlnzbhVZ/fq6NW8f6AovLITBcFkJwqCyU4UBJOdKAgmO1EQTHaiIJjsREGwzj5Eeers8+fPN+PTpk0z48uXLzfjZZanHr127VozvmjRIjO+YMGC1Njq1avNttdiHd2TK9lFZB+APgAXAVxQ1bZKdIqIKq8SV/aHVfVIBfZDRFXE9+xEQeRNdgXwFxH5VETaB/sBEWkXkc0isjnnsYgoh7wv4x9Q1QMi0gBgvYh8oaofD/wBVe0A0AGUe8JJoutdriu7qh5IvvYAWAvAniaViAqTOdlFpE5Exl1+DGAWgB2V6hgRVVael/GNANYm9ecRAP5bVf+nIr0qoTx113vuuceM9/X1mfFHH33UjH/wwQdX3afrQWdnpxmfN29easyrs3uuxSWfMye7qu4BYP8VE1FpsPRGFASTnSgIJjtREEx2oiCY7ERBcIhrDYwcOdKMe6W306dPZz520SWiPFNJT5061Yy3tLRkPnZzc7PZtqury4x7Sz5/8803ZrwIvLITBcFkJwqCyU4UBJOdKAgmO1EQTHaiIJjsREFcU3V2q2bs1T29mq4Xt+rRw4cPN9t6Nd3x48eb8a1bt5pxi1dH95Ymrub+vXN+5513mvH6+nozvmfPntRYnnsXgGtzqmle2YmCYLITBcFkJwqCyU4UBJOdKAgmO1EQTHaiIK6pOrtV0y1y/LBXa540aZIZP3XqlBn3xsPnUe168YULF6rWdty4cWZ8woQJqbFz585l6tNlFy9eNOPePALW/QfevrPilZ0oCCY7URBMdqIgmOxEQTDZiYJgshMFwWQnCuKaqrNbHn/8cTM+Y8YMM+4te7xr167U2KxZs8y2bW1tZnzdunVm3KvDX6+8+xO8eyus3/n58+cz9WmovHsvqlVLt7hXdhF5Q0R6RGTHgG31IrJeRDqTrxOr200iymsoL+OXA3jsim3PA9igqncA2JB8T0Ql5ia7qn4MoPeKzXMBrEgerwDwZIX7RUQVlvU9e6OqdiePDwJoTPtBEWkH0J7xOERUIbk/oFNVFZHUTyNUtQNABwBYP0dE1ZW19HZIRJoAIPnaU7kuEVE1ZE32dQAWJY8XAXi3Mt0homoRrx4oIqsAPARgEoBDAH4F4B0AfwLwDwD2A5ivqld+iDfYvnK9jL/ppptSYx9++KHZtq6uzowfP37cjDc0NKTGuru7U2OAP6+8tz77xIl2ZdPq+9ixY8223nz73tzsXt/OnDmTGrPGmwPAoUOHzPjevXvNuOWrr74y497a8F6dvrfXToelS5emxvbv32+29ajqoIPp3ffsqrowJfRIrh4RUU3xdlmiIJjsREEw2YmCYLITBcFkJwrCLb1V9GA5S2+bNm1KjY0ePdps6w0T9UpU1nBKr1TS1NRkxr1pjb0pk6dMmZIa80qK3nTNecuC1v69IaonT54041YpFrBLd6NGjTLbes/Lm4LbK1lapeJnnnnGbOtJK73xyk4UBJOdKAgmO1EQTHaiIJjsREEw2YmCYLITBVGqqaQbG1NntwIAtLS0pMZ27txptvXq6GfPnjXjVl3Vq1VbwzwBv57s7d+qV+e9/8AbyuktJ20tXey19e4/OHbsmBk/ceJEasy7d+H06dO54rt37zbjeZayzopXdqIgmOxEQTDZiYJgshMFwWQnCoLJThQEk50oiFLV2b2pg3fs2JEaGz9+vNnWqzd745OterQ3Ntrbt1fj95Yutp6btzSwN979hhtuMON55kPw6ujedMzeeHZr/zfeeGPmtoBfp+/s7DTj999/f2ps9uzZZltvefE0vLITBcFkJwqCyU4UBJOdKAgmO1EQTHaiIJjsREGUqs5+++23m/HJkyenxrx6sTd22ltW+ciRI6kxb1y1V5P1xox7tXIr7rUdNsz+/967h8A7r9ZYe6+WffTo0VzHtnjPy/udefPpe+PVv/jii9TY4cOHzbZZuVd2EXlDRHpEZMeAbS+KyAER2Zr8m1OV3hFRxQzlZfxyAI8Nsv13qtqa/Hu/st0iokpzk11VPwZg37dIRKWX5wO6n4vItuRlfurCWCLSLiKbRWRzjmMRUU5Zk/0PAKYDaAXQDeA3aT+oqh2q2qaqbRmPRUQVkCnZVfWQql5U1UsAlgGYWdluEVGlZUp2ERm4BvE8AOljT4moFNw6u4isAvAQgEki0gXgVwAeEpFWAApgH4CfVqIzra2tZtyaX72np8ds69VV6+rqzLhV0/XmEPfGs3t1dm/MuHWPgDdnvXd/gbeGuseq43v3Rnj1Zm/d+zFjxqTGvHPuPW/vHgBv/7fccktqzFvjICs32VV14SCbX69CX4ioini7LFEQTHaiIJjsREEw2YmCYLITBVGqIa4PPvigGbfKY960wl7pLU+JyZtu2SoBAf5QzREj7F+TVd7y+uYtF+0NkfVKd1bfvCGuXvnKm2Lbmpr866+/Nts2NDTkOra3ZLM1lXVbm32z6UcffWTG0/DKThQEk50oCCY7URBMdqIgmOxEQTDZiYJgshMFUao6+yOPPGLGRSQ1lnfIoleHt6YGzjOdMuDX0b0hslbcmyraG5578803m3HvuVm1dO95e8twezV+a3ivt4S3N2Tam/Z8xowZZnzXrl2psdtuu81smxWv7ERBMNmJgmCyEwXBZCcKgslOFASTnSgIJjtREKWqsy9dutSML1u2LDXmjT/2ltD1xlZbNV1vzLhXJ58wYYIZt8Y+A3bfrHsT8u4byHd/gnfs5uZmM+71zdq/9/fi3X/Q2dlpxr1p0bds2ZIa8+ZmyIpXdqIgmOxEQTDZiYJgshMFwWQnCoLJThQEk50oiFLV2b26qTWHubessSdPLdyrZXtjp73x8F4t23ru3r69ewS8uHf/gnVuvKWJjx07ZsbzzGnv/U5OnTplxvv6+sz49u3bzfjUqVNTY/v37zfbZuVe2UWkRUT+KiKfichOEVmcbK8XkfUi0pl8nViVHhJRRQzlZfwFAEtU9S4A9wH4mYjcBeB5ABtU9Q4AG5Lviaik3GRX1W5V3ZI87gPwOYApAOYCWJH82AoAT1ark0SU31W9ZxeRqQB+CGATgEZV7U5CBwE0prRpB9CevYtEVAlD/jReRMYCWAPgF6p6YmBM+z8hGvRTIlXtUNU2VbVXqyOiqhpSsovISPQn+kpV/XOy+ZCINCXxJgD2dJxEVCj3Zbz0105eB/C5qv52QGgdgEUAXk6+vpu3M94UulZ5LM+Sy4Bf9jt+/Hjmtl7pzBtO6T03q7yVZ0llwC9penHr+NYS3ABw9OhRM+4tN713797U2OTJk8223pLM3nnzloQ+fPhwaswrC2Y1lPfsPwLwYwDbRWRrsu0F9Cf5n0TkJwD2A5hflR4SUUW4ya6qGwGkXTrsVR2IqDR4uyxREEx2oiCY7ERBMNmJgmCyEwVRqiGuXu3SGq6Zpy3gD5e0hmPmnY7Z65v33Kz7D7yhu97wXC/usdr39vaabb3hs14tfPr06ZmPPW7cODPuDf31poO2jm/dH5AHr+xEQTDZiYJgshMFwWQnCoLJThQEk50oCCY7URClqrPv3r3bjFs1Y68m640Z9+qq1pj0vLVsb1y3V6fPM42213dvLL13bOseAW+cv1er9vo2cWL6hMdendy798H7W/WmyZ4xY0Zq7M033zTbZsUrO1EQTHaiIJjsREEw2YmCYLITBcFkJwqCyU4URKnq7Dt37jTj1jziXp19zJgxZtwbk+7V6S0jRtin2Vse2FouGrDr1V6Nvr6+3ox77b06veXEiRNm/MyZM2bc63uetQS8eyMaGhrMeE+PvWaKdV43btxots2KV3aiIJjsREEw2YmCYLITBcFkJwqCyU4UBJOdKIihrM/eAuCPABoBKIAOVf29iLwI4F8AXF5o+gVVfT9PZw4ePGjGrTHCXl3TGzt9/vx5M27VfL16rlfj99YZ98ZGW2vHe+uEe3PSe/cInD171ow3Njamxry5+j1ejd/av9fW+3vwnrc1lh4Aurq6UmP79u0z22Y1lJtqLgBYoqpbRGQcgE9FZH0S+52q/ltVekZEFTWU9dm7AXQnj/tE5HMAU6rdMSKqrKt6zy4iUwH8EMCmZNPPRWSbiLwhIoO+bhGRdhHZLCKbc/WUiHIZcrKLyFgAawD8QlVPAPgDgOkAWtF/5f/NYO1UtUNV21S1rQL9JaKMhpTsIjIS/Ym+UlX/DACqekhVL6rqJQDLAMysXjeJKC832aV/+M/rAD5X1d8O2N404MfmAdhR+e4RUaUM5dP4HwH4MYDtIrI12fYCgIUi0or+ctw+AD/N2xlvGOm2bdtSY0888YTZ9ssvvzTj3rTFVgnLG17rla+88pg3nNLqe1NTU2psKMf2plT2hoJaUzZ7Q1y9fY8ePdqMWyVPqyQI+GXB5uZmM97X12fGFy5caMarYSifxm8EMNhZz1VTJ6La4h10REEw2YmCYLITBcFkJwqCyU4UBJOdKAjJs9zvVR9MpGoHu++++8y4tUQuANx6661m3DpP3hBWrx7sLdmcp9btHdurZXtDg/MMgfWm0M67DLd1bO+ce/ves2ePGV+9erUZP3funBnPQ1UH/aXyyk4UBJOdKAgmO1EQTHaiIJjsREEw2YmCYLITBVHrOvthAPsHbJoE4EjNOnB1ytq3svYLYN+yqmTfblPVyYMFaprs3zu4yOayzk1X1r6VtV8A+5ZVrfrGl/FEQTDZiYIoOtk7Cj6+pax9K2u/APYtq5r0rdD37ERUO0Vf2YmoRpjsREEUkuwi8piI/L+I7BaR54voQxoR2Sci20Vka9Hr0yVr6PWIyI4B2+pFZL2IdCZf7bWBa9u3F0XkQHLutorInIL61iIifxWRz0Rkp4gsTrYXeu6MftXkvNX8PbuIDAewC8A/A+gC8AmAhar6WU07kkJE9gFoU9XCb8AQkX8CcBLAH1X1B8m2fwXQq6ovJ/9RTlTVpSXp24sATha9jHeyWlHTwGXGATwJ4BkUeO6Mfs1HDc5bEVf2mQB2q+oeVT0PYDWAuQX0o/RU9WMAvVdsngtgRfJ4Bfr/WGoupW+loKrdqroledwH4PIy44WeO6NfNVFEsk8B8LcB33ehXOu9K4C/iMinItJedGcG0aiq3cnjgwDsdYxqz13Gu5auWGa8NOcuy/LnefEDuu97QFXvBTAbwM+Sl6ulpP3vwcpUOx3SMt61Msgy498q8txlXf48ryKS/QCAlgHfNyfbSkFVDyRfewCsRfmWoj50eQXd5GtPwf35VpmW8R5smXGU4NwVufx5Ecn+CYA7RGSaiIwCsADAugL68T0iUpd8cAIRqQMwC+VbinodgEXJ40UA3i2wL99RlmW805YZR8HnrvDlz1W15v8AzEH/J/JfAvhlEX1I6dc/Avi/5N/OovsGYBX6X9Z9g/7PNn4C4GYAGwB0AvhfAPUl6tt/AdgOYBv6E6upoL49gP6X6NsAbE3+zSn63Bn9qsl54+2yREHwAzqiIJjsREEw2YmCYLITBcFkJwqCyU4UBJOdKIi/Azz6rWa3N4ABAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preciso pegar a quantidade de pixels que cada imagem possui pois isso determinará a quantidade de Neurônios de Input que teremos\n",
        "# Calculando o total de pixels da imagem, multiplicando as dimensões da imagem\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "print(num_pixels)\n",
        "\n",
        "# Transforma os valores dos pixels para float32\n",
        "X_train2 = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test2 = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# Normalizando os valores dos pixels entre 0 e 1\n",
        "X_train2 = X_train2 / 255\n",
        "X_test2 = X_test2 / 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKcOKK1OCnry",
        "outputId": "f8adb602-6a6e-4a17-f2a5-9d1b66da916b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformando nossos labels (os y) em categóricos para podermos usá-los como uma matriz\n",
        "# Em outras palavras, estamos transformando o y em ONE HOT VECTOR\n",
        "y_train_h = np_utils.to_categorical(y_train)\n",
        "y_test_h = np_utils.to_categorical(y_test)\n",
        "\n",
        "# Vamos ver um Exemplo: vimos anteriormente que o número no índice 100 é 5, agora veremos ele representado no formato de matriz\n",
        "print(y_train[4000])\n",
        "print(y_train_h[4000])\n",
        "\n",
        "# Vendo qual a categoria do índice 4000 das variáveis teste\n",
        "print(y_test_h[4000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4A9d3cMC2Wt",
        "outputId": "ac797b3c-9669-4d85-90bb-b60d13ebcbd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trazendo o modelo VGG16\n",
        "model = VGG16(weights=None, input_shape=(32,32,3))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrFxscdv0D7C",
        "outputId": "079f4235-eb89-449f-d164-9d1c7d83eafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              2101248   \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37,694,248\n",
            "Trainable params: 37,694,248\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando a 2ª Rede do Exercício\n",
        "model2 = Sequential([\n",
        "    Dense(units=784, kernel_initializer='normal', input_dim=784, activation='relu'), # 1ª camada\n",
        "    Dense(units=1024, kernel_initializer='normal', activation='relu'), # 2ª camada\n",
        "    Dense(units=2048, kernel_initializer='normal', activation='relu'), # 3ª camada\n",
        "    Dense(units=2048, kernel_initializer='normal', activation='relu'), # 4ª camada\n",
        "    Dense(units=10,kernel_initializer='normal', activation='softmax') # Camada de Saída\n",
        "])\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zu1dmjp6KpR",
        "outputId": "f3bda435-3d2c-47b8-b3f7-902153f6cf6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 784)               615440    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1024)              803840    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2048)              2099200   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2048)              4196352   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,735,322\n",
            "Trainable params: 7,735,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # compila o modelo criado\n",
        "result = model2.fit(X_train2, y_train_h, validation_data=(X_test2,y_test_h), epochs=20, verbose=1, batch_size = 100) # executa o treinamento"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9P_Vt-gGInG",
        "outputId": "53551f56-2df5-4eaf-96f4-46135755e3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "600/600 [==============================] - 4s 5ms/step - loss: 0.5313 - accuracy: 0.8252 - val_loss: 0.4411 - val_accuracy: 0.8437\n",
            "Epoch 2/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.3643 - accuracy: 0.8671 - val_loss: 0.3830 - val_accuracy: 0.8626\n",
            "Epoch 3/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.3224 - accuracy: 0.8800 - val_loss: 0.3527 - val_accuracy: 0.8719\n",
            "Epoch 4/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.3013 - accuracy: 0.8863 - val_loss: 0.3510 - val_accuracy: 0.8776\n",
            "Epoch 5/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2853 - accuracy: 0.8927 - val_loss: 0.3699 - val_accuracy: 0.8724\n",
            "Epoch 6/20\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.2743 - accuracy: 0.8978 - val_loss: 0.3509 - val_accuracy: 0.8765\n",
            "Epoch 7/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2624 - accuracy: 0.9009 - val_loss: 0.3470 - val_accuracy: 0.8764\n",
            "Epoch 8/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2495 - accuracy: 0.9051 - val_loss: 0.3553 - val_accuracy: 0.8770\n",
            "Epoch 9/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2400 - accuracy: 0.9084 - val_loss: 0.3361 - val_accuracy: 0.8896\n",
            "Epoch 10/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2265 - accuracy: 0.9145 - val_loss: 0.3701 - val_accuracy: 0.8787\n",
            "Epoch 11/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2230 - accuracy: 0.9157 - val_loss: 0.3253 - val_accuracy: 0.8908\n",
            "Epoch 12/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2065 - accuracy: 0.9215 - val_loss: 0.3430 - val_accuracy: 0.8912\n",
            "Epoch 13/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2059 - accuracy: 0.9225 - val_loss: 0.3605 - val_accuracy: 0.8832\n",
            "Epoch 14/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1961 - accuracy: 0.9251 - val_loss: 0.3552 - val_accuracy: 0.8888\n",
            "Epoch 15/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1882 - accuracy: 0.9278 - val_loss: 0.3492 - val_accuracy: 0.8950\n",
            "Epoch 16/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1810 - accuracy: 0.9310 - val_loss: 0.3704 - val_accuracy: 0.8902\n",
            "Epoch 17/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1694 - accuracy: 0.9343 - val_loss: 0.3990 - val_accuracy: 0.8906\n",
            "Epoch 18/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1696 - accuracy: 0.9348 - val_loss: 0.3762 - val_accuracy: 0.8916\n",
            "Epoch 19/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1612 - accuracy: 0.9383 - val_loss: 0.4012 - val_accuracy: 0.8899\n",
            "Epoch 20/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1592 - accuracy: 0.9386 - val_loss: 0.4261 - val_accuracy: 0.8916\n"
          ]
        }
      ]
    }
  ]
}